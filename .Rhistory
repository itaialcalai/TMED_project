rra_result <- RRA(de_matrix)
# Extract the integrated DEGs based on the result
integrated_degs <- rownames(rra_result$aggregatedRank)
print(integrated_degs)
},
error = function(e) {
# Error handling code
print("An error occurred.")
print(e)
}
)
}
# Define a class to represent a study
Study <- setRefClass(
"Study",
fields = list(
name = "character",
country = "character",
tissue = "character",
n = "integer",
group_string = "character",
file_format = "character"
),
methods = list(
initialize = function(name, country, tissue, n, group_string, file_format) {
name <<- name
country <<- country
tissue <<- tissue
n <<- n
group_string <<- group_string
file_format <<- file_format
}
)
)
# Function to read the config file and populate the studies list
read_config_file <- function(filename) {
studies <- list()
con <- file(filename, "r")
while (length(line <- readLines(con, n = 1)) > 0) {
line <- trimws(line)
if (nchar(line) > 0) {
elements <- strsplit(line, ",")[[1]]
if (length(elements) == 6) {
name <- elements[1]
country <- elements[2]
tissue <- elements[3]
n <- as.integer(elements[4])
group_string <- elements[5]
file_format <- elements[6]
study <- Study$new(name, country, tissue, n, group_string, file_format)
studies <- c(studies, study)
} else {
cat(paste("Ignoring invalid line:", line, "\n"))
}
}
}
close(con)
return(studies)
}
# Create a list to store study objects
studies <- list()
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
print("Reading config file")
studies <- read_config_file("Configs_test.txt")
num_studies <- length(studies)
counter <- 0
print(paste("Number of studies:", num_studies))
print("Performing analysis")
run_DEGs_analysis(studies)
run_DEGs_analysis <- function(studies) {
tryCatch(
{
library(GEOquery)
library(randomForest)
# Perform differential expression analysis for each dataset
de_results <- list()
# Download and store datasets
for (i in 1:length(studies)) {
study <- studies[[i]]
gset <- getGEO(study$name, GSEMatrix = TRUE, AnnotGPL = TRUE)
if (length(gset) > 1) idx <- grep(study$file_format, attr(gset, "names")) else idx <- 1
gset <- gset[[idx]]
# Make proper column names to match toptable
fvarLabels(gset) <- make.names(fvarLabels(gset))
# Group membership for all samples
gsms <- study$group_string
sml <- strsplit(gsms, split = "")[[1]]
# Filter out excluded samples (marked as "X")
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[, sel]
# filter out excluded samples (marked as "X")
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[ ,sel]
# log2 transformation
ex <- exprs(gset)
qx <- as.numeric(quantile(ex, c(0., 0.25, 0.5, 0.75, 0.99, 1.0), na.rm = TRUE))
LogC <- (qx[5] > 100) || (qx[6] - qx[1] > 50 && qx[2] > 0)
if (LogC) {
ex[which(ex <= 0)] <- NaN
exprs(gset) <- log2(ex)
}
# assign samples to groups and set up the design matrix
gs <- factor(sml)
groups <- make.names(c("T2D", "normal"))
levels(gs) <- groups
gset$group <- gs
design <- model.matrix(~group + 0, gset)
colnames(design) <- levels(gs)
gset <- gset[complete.cases(exprs(gset)), ]  # Skip missing values
fit <- lmFit(gset, design)  # Fit linear model
# Set up contrasts of interest and recalculate model coefficients
cts <- paste(groups[1], groups[2], sep = "-")
cont.matrix <- makeContrasts(contrasts = cts, levels = design)
fit2 <- contrasts.fit(fit, cont.matrix)
# Compute statistics and table of top significant genes
fit2 <- eBayes(fit2, 0.01)
print("111")
# Select differentially expressed genes based on a threshold (e.g., adjusted p-value or fold change)
de_results[[i]] <- decideTests(fit2)
}
# Combine the DEG results from each dataset into a single matrix
de_matrix <- do.call(cbind, de_results)
# Run RobustRankAggreg on the DEG matrix
rra_result <- RRA(de_matrix)
# Extract the integrated DEGs based on the result
integrated_degs <- rownames(rra_result$aggregatedRank)
print(integrated_degs)
},
error = function(e) {
# Error handling code
print("An error occurred.")
print(e)
}
)
}
# Create a list to store study objects
studies <- list()
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
print("Reading config file")
studies <- read_config_file("Configs_test.txt")
num_studies <- length(studies)
counter <- 0
print(paste("Number of studies:", num_studies))
print("Performing analysis")
run_DEGs_analysis(studies)
# Create a list to store study objects
studies <- list()
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
print("Reading config file")
studies <- read_config_file("Configs_test.txt")
num_studies <- length(studies)
counter <- 0
print(paste("Number of studies:", num_studies))
print("Performing analysis")
run_DEGs_analysis(studies)
run_DEGs_analysis <- function(studies) {
tryCatch(
{
library(GEOquery)
library(randomForest)
# Perform differential expression analysis for each dataset
de_results <- list()
# Download and store datasets
for (i in 1:length(studies)) {
study <- studies[[i]]
gset <- getGEO(study$name, GSEMatrix = TRUE, AnnotGPL = TRUE)
if (length(gset) > 1) idx <- grep(study$file_format, attr(gset, "names")) else idx <- 1
gset <- gset[[idx]]
# Make proper column names to match toptable
fvarLabels(gset) <- make.names(fvarLabels(gset))
# Group membership for all samples
gsms <- study$group_string
sml <- strsplit(gsms, split = "")[[1]]
# Filter out excluded samples (marked as "X")
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[, sel]
# filter out excluded samples (marked as "X")
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[ ,sel]
# log2 transformation
ex <- exprs(gset)
qx <- as.numeric(quantile(ex, c(0., 0.25, 0.5, 0.75, 0.99, 1.0), na.rm = TRUE))
LogC <- (qx[5] > 100) || (qx[6] - qx[1] > 50 && qx[2] > 0)
if (LogC) {
ex[which(ex <= 0)] <- NaN
exprs(gset) <- log2(ex)
}
# assign samples to groups and set up the design matrix
gs <- factor(sml)
groups <- make.names(c("T2D", "normal"))
levels(gs) <- groups
gset$group <- gs
design <- model.matrix(~group + 0, gset)
colnames(design) <- levels(gs)
gset <- gset[complete.cases(exprs(gset)), ]  # Skip missing values
fit <- lmFit(gset, design)  # Fit linear model
# Set up contrasts of interest and recalculate model coefficients
cts <- paste(groups[1], groups[2], sep = "-")
cont.matrix <- makeContrasts(contrasts = cts, levels = design)
fit2 <- contrasts.fit(fit, cont.matrix)
# Compute statistics and table of top significant genes
fit2 <- eBayes(fit2, 0.01)
print("111")
# Select differentially expressed genes based on a threshold (e.g., adjusted p-value or fold change)
de_results[[i]] <- decideTests(fit2)
}
print(de_results)
# Combine the DEG results from each dataset into a single matrix
de_matrix <- do.call(cbind, de_results)
# Run RobustRankAggreg on the DEG matrix
rra_result <- RRA(de_matrix)
# Extract the integrated DEGs based on the result
integrated_degs <- rownames(rra_result$aggregatedRank)
print(integrated_degs)
},
error = function(e) {
# Error handling code
print("An error occurred.")
print(e)
}
)
}
# Create a list to store study objects
studies <- list()
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
print("Reading config file")
studies <- read_config_file("Configs_test.txt")
num_studies <- length(studies)
counter <- 0
print(paste("Number of studies:", num_studies))
print("Performing analysis")
run_DEGs_analysis(studies)
run_DEGs_analysis(studies)
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
print(top1000_paths)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
print(top1000_file)
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
print(top1000_paths)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_files)) {
top1000_file <- top1000_files[j]
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
temp_list[[j]] <- top1000_data
}
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_files)) {
top1000_file <- top1000_files[j]
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
temp_list[[j]] <- top1000_data
}
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
top1000_file <- top1000_files[j]
top1000_data <- read.delim(top1000_file, header = TRUE, stringsAsFactors = FALSE)
temp_list[[j]] <- top1000_data
}
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
temp_list[[j]] <- top1000_data
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
temp_list[[j]] <- top1000_data
}
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
print(top1000_paths)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
temp_list[[j]] <- top1000_data
}
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
temp_list[[j]] <- top1000_data
}
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
de_results <- list()
top1000_path <- top1000_paths[[i]]
top1000_path <- top1000_paths[i]
View(top1000_paths)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
temp_file <- top1000_file[i]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
temp_file <- top1000_paths[i]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
# Read the top1000 file
temp_file <- top1000_paths[[i]]
# Read the top1000 file
temp_file <- top1000_paths[[i]]
print(temp_file)
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
print(top1000_paths)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
temp_list[[j]] <- top1000_data
}
de_results[[i]] <- top1000_data
# Append the data to the combined table
# combined_table <- rbind(combined_table, top1000_data)
}
View(de_results)
de_results <- list()
View(temp_list)
# Read the configuration file containing paths to top1000 files
working_dir <- "C:\\Users\\itaia\\OneDrive\\Project_TMED"
setwd(working_dir)
current_dir <- getwd()
print(current_dir)
config_file <- "Configs_top1000.txt"
top1000_paths <- read.delim(config_file, header = FALSE, stringsAsFactors = FALSE)
de_results <- list()
# Loop through each top1000 file and combine the data
for (i in 1:length(top1000_paths)) {
# Read the top1000 file
top1000_file <- top1000_paths[[i]]
print(top1000_file)
# Create a temporary list to store the data for each file
temp_list <- list()
# Read each top1000 file and store the data
for (j in 1:length(top1000_file)) {
temp_file <- top1000_file[j]
top1000_data <- read.delim(temp_file, header = TRUE, stringsAsFactors = FALSE)
print(top1000_data)
de_results[[j]] <- top1000_data
}
}
# Combine the DEG results from each dataset into a single matrix
de_matrix <- do.call(cbind, de_results)
# Run RobustRankAggreg on the DEG matrix
rra_result <- RRA(de_matrix)
library(BiocManager)
library(GEOquery)
library(limma)
# Run RobustRankAggreg on the DEG matrix
rra_result <- RRA(de_matrix)
View(de_matrix)
install.packages("RobustRankAggreg")
library(RobustRankAggreg)
# Run RobustRankAggreg on the DEG matrix
rra_result <- RRA(de_matrix)
# Combine the DEG results from each dataset into a single matrix
glist <- do.call(cbind, de_results)
result <- aggregateRanks(glist = glist, N = 1000, method = "stuart")
View(de_results)
result <- aggregateRanks(glist = de_results, N = 1000, method = "stuart")
View(de_matrix)
View(de_results)
